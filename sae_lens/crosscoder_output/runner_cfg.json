{"sae": {"d_in": 1024, "d_sae": 2048, "dtype": "float32", "device": "cpu", "apply_b_dec_to_input": false, "normalize_activations": "none", "reshape_activations": "none", "metadata": {"sae_lens_version": "6.21.0", "sae_lens_training_version": "6.21.0"}, "decoder_init_norm": 0.1, "d_out": 1024, "d_model": 512, "n_input_layers": 2, "n_output_layers": 2, "hook_names_in": "", "hook_names_out": "", "architecture": "crosscoder"}, "model_name": "EleutherAI/pythia-70m", "model_class_name": "HookedTransformer", "hook_name": "blocks.0.hook_mlp_out", "hook_eval": "NOT_IN_USE", "hook_head_index": null, "hook_names_in": ["blocks.1.hook_resid_post,blocks.2.hook_resid_post"], "hook_names_out": ["blocks.3.hook_resid_post,blocks.4.hook_resid_post"], "d_model": 512, "dataset_path": "NeelNanda/c4-tokenized-2b", "dataset_trust_remote_code": true, "streaming": true, "is_dataset_tokenized": true, "context_size": 128, "use_cached_activations": false, "cached_activations_path": null, "from_pretrained_path": null, "n_batches_in_buffer": 64, "training_tokens": 819200, "store_batch_size_prompts": 32, "seqpos_slice": [null], "disable_concat_sequences": false, "sequence_separator_token": "bos", "device": "cpu", "act_store_device": "cpu", "seed": 42, "dtype": "float32", "prepend_bos": true, "autocast": false, "autocast_lm": false, "compile_llm": false, "llm_compilation_mode": null, "compile_sae": false, "sae_compilation_mode": null, "train_batch_size_tokens": 8192, "adam_beta1": 0.9, "adam_beta2": 0.999, "lr": 0.0003, "lr_scheduler_name": "constant", "lr_warm_up_steps": 0, "lr_end": 2.9999999999999997e-05, "lr_decay_steps": 0, "n_restart_cycles": 1, "dead_feature_window": 1000, "feature_sampling_window": 2000, "dead_feature_threshold": 1e-08, "n_eval_batches": 10, "eval_batch_size_prompts": null, "logger": {"log_to_wandb": false, "log_activations_store_to_wandb": false, "log_optimizer_state_to_wandb": false, "wandb_project": "sae_lens_training", "wandb_id": null, "run_name": "crosscoder-2048-LR-0.0003-Tokens-8.192e+05", "wandb_entity": null, "wandb_log_frequency": 10, "eval_every_n_wandb_logs": 100}, "n_checkpoints": 0, "checkpoint_path": "checkpoints/6hqaf1we", "save_final_checkpoint": false, "output_path": "./crosscoder_output", "resume_from_checkpoint": null, "verbose": true, "model_kwargs": {}, "model_from_pretrained_kwargs": {"center_writing_weights": false}, "sae_lens_version": "6.21.0", "sae_lens_training_version": "6.21.0", "exclude_special_tokens": false}